{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Inference About Means and Proportions with Two Populations\n",
    "In previous sessions we learnt how to develop interval estimates and conduct hypothesis tests for situations involving a single population mean. We continue our discussion of statistical inference by showing how interval estimates and hypothesis tests can be developed for situations involving two populations when the dif- ference between the two population means or the two population proportions is of prime im- portance.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "- Type I - Type II errors\n",
    "\n",
    "- Comparing population means in the case population variances are known\n",
    "\n",
    "- Comparing population means in the case population variances are not known\n",
    "\n",
    "### Inferences About the Difference Between Two Population Means: $\\sigma_{1}$ and $\\sigma_{2}$ Known\n",
    "\n",
    "__Scenerio__\n",
    "\n",
    "Suppose we noticed that Flatiron ATL datascience graduates find jobs a lot quicker than the NYC campus. Adam Enbar believes that this is because ATL student's number of years spent in industry is higher than the NYC campus. Suppose we are asked to investigate this situation to find out whether there is any statistically significant difference between the mean number of years spent in industry of the students from two campuses. \n",
    "\n",
    "$\\mu_{1} $ = mean population 1. (the mean # of years among all the ATL datascience students.)\n",
    "\n",
    "$\\mu_{2} $ = mean population 2. (The mean # of years among all the NYC datascience students.)\n",
    "\n",
    "$\\bar{x}_{1}$ = sample mean number of years of experience for the $n_1$ ATL campus students. \n",
    "\n",
    "$\\bar{x}_{2}$ = sample mean number of years of experience for the $n_{2}$ NYC campus students.\n",
    "\n",
    "$ \\bar{x}_{1} - \\bar{x}_{2}$ is called point estimator of the difference between two population.\n",
    "\n",
    "\n",
    "One can show that the standard error for the $\\bar{x}_{1} - \\bar{x}_{2}$ is \n",
    "\n",
    "$$ \\sigma_{\\bar{x}_{1} - \\bar{x}_{2}} = \\sqrt{\\frac{\\sigma_{1}^{2}}{n_{1}} + \\frac{\\sigma_{2}^{2}}{n_{2}}}$$\n",
    "\n",
    "\n",
    "> Recall that the standard error is just the standard deviation of the sampling distribution of $\\bar{x}_{1} - \\bar{x}_{2}$\n",
    "\n",
    "If we want to find an interval estimates, then\n",
    "\n",
    "$$\\text{Interval Estimates} = (\\bar{x}_{1} - \\bar{x}_{2}) \\pm \\text{Margin of Error} $$\n",
    "\n",
    "where margin of error is \n",
    "\n",
    "$$ \\text{Margin of Error} = z_{\\alpha/2}\\sigma_{\\bar{x}_{1} - \\bar{x}_{2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Form Null and Alternative Hypothesis\n",
    "|\n",
    "\n",
    "|  your work is here -  take $\\alpha = 0.05$\n",
    "\n",
    "|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interval estimate for the differences of the means is [0.35170869408801986, 5.098087928526001]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2020)\n",
    "\n",
    "## Note that here we assumed that the populations are normally distributed\n",
    "## What would happen if this wouldn't be the case?\n",
    "\n",
    "\n",
    "nyc_campus = np.random.normal(loc = 4, scale = 4, size = 13)\n",
    "\n",
    "ATL_campus = np.random.normal(loc = 6, scale = 2, size = 17)\n",
    "\n",
    "x1_bar = ATL_campus.mean()\n",
    "x2_bar = nyc_campus.mean()\n",
    "n1 = len(ATL_campus)\n",
    "n2 = len(nyc_campus)\n",
    "sigma1 = 2\n",
    "sigma2 = 4\n",
    "\n",
    "std_error = np.sqrt(sigma1**2 / (n1) + sigma2**2 / (n2)) \n",
    "\n",
    "\n",
    "## where 1.96 come from? Hint: what is z_{alpha/2} for alpha = 0.05?\n",
    "margin_error = std_error * 1.96\n",
    "\n",
    "lower_bound = x1_bar - x2_bar - margin_error\n",
    "\n",
    "upper_bound = x1_bar - x2_bar + margin_error\n",
    "\n",
    "\n",
    "## How can we interpret this interval?\n",
    "\n",
    "print('interval estimate for the differences of the means is [{}, {}]'.format(lower_bound, upper_bound))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that instead of an estimation interval we could also find a z-statistic. Recall that the z-score is given by:\n",
    "\n",
    "$$  z = \\frac{(\\bar{x}_{1} - \\bar{x}_{2}) - D_{0}}{\\sqrt{\\frac{\\sigma_{1}^{2}}{n_{1}} + \\frac{\\sigma_{2}^{2}}{n_{2}}}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z-statistics is 2.25047364585234\n",
      "Probability of getting z smaller than 2.25047364585234 is 0.9877905526911385\n",
      "Probability of getting such z-value or higher by just chance is 0.012209447308861532\n"
     ]
    }
   ],
   "source": [
    "## Let's calculate the z-score with null hypothesis D_0 = 0 \n",
    "\n",
    "z = (x1_bar - x2_bar) / std_error\n",
    "\n",
    "print('z-statistics is {}'.format(z))\n",
    "\n",
    "z_cdf = stats.norm.cdf(z)\n",
    "\n",
    "print('Probability of getting z smaller than {} is {}'.format(z, z_cdf))\n",
    "\n",
    "p_value = 1 - z_cdf\n",
    "\n",
    "print('Probability of getting such z-value or higher by just chance is {}'.format(p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferences about the difference between two population means to the case when the two population standard deviations, $\\sigma_{1}$ and $\\sigma_{2}$, are unknown.\n",
    "\n",
    "Note tha most of the time the population variances are not known. Then we can use the sample standard deviations instead of population variances. Then we will use T-distributions in our estimations.\n",
    "\n",
    "__Interval Estimates__\n",
    "\n",
    "$$ \\text{Interval Estimates} = (\\bar{x}_{1} - \\bar{x}_{2}) \\pm t_{\\alpha/2} \\sqrt{\\frac{s_{1}^{2}}{n_{1}} + \\frac{s_{2}^{2}}{n_{2}}} $$\n",
    "\n",
    "\n",
    "In fact, this test is called the Welch test and here the use of T-distribution is an approximation. This test is preferred here because it doesn't assume that population's variance is the same and this test is relatively simpler. The only challenge here is to estimate the degrees of freedom for the T-distribution. But it is known that the formula \n",
    "\n",
    "$$\\text{df}  = \\frac{\\big(\\frac{s_{1}^{2}}{n_{1}} + \\frac{s_{2}^{2}}{n_{2}}\\big)^{2}}{\\frac{1}{n_{1}-1}\\big(\\frac{s_{1}^{2}}{n_{1}}\\big)^{2} + \\frac{1}{n_{2}-1}\\big(\\frac{s_{2}^{2}}{n_{2}}\\big)^{2}}$$\n",
    "\n",
    "Then T-statistics is given by \n",
    "\n",
    "$$   t = \\frac{(\\bar{x}_{1} - \\bar{x}_{2}) - D_{0}}{\\sqrt{\\frac{s_{1}^{2}}{n_{1}} + \\frac{s_{2}^{2}}{n_{2}}}} $$ and the degrees of freedom for $t$ is given as above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approximate degrees of freedom is 25.977149729404687\n"
     ]
    }
   ],
   "source": [
    "## Let's calculate this for the example above:\n",
    "\n",
    "s1_squared = ATL_campus.var(ddof = 1)\n",
    "s2_squared = ATL_campus.var(ddof = 1)\n",
    "\n",
    "sn1 = s1_squared/n1\n",
    "\n",
    "sn2 = s2_squared/n2\n",
    "\n",
    "df_num = (sn1 + sn2)**2\n",
    "\n",
    "df_denom = (sn1)**2 / (n1-1) + (sn2)**2 / (n2-1)\n",
    "\n",
    "df = df_num/df_denom\n",
    "\n",
    "print('approximate degrees of freedom is {}'.format(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistics is found as 3.8463632094228424\n",
      "p_value from cdf 0.0006978438980359332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=2.3941130363637915, pvalue=0.028601412116788048)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## find t-statistics\n",
    "\n",
    "t = (x1_bar - x2_bar)/ np.sqrt(sn1 + sn2)\n",
    "\n",
    "print('t-statistics is found as {}'.format(t))\n",
    "\n",
    "p_value = stats.t.sf(t, df = df)*2\n",
    "\n",
    "print('p_value from cdf {}'.format(p_value))\n",
    "stats.ttest_ind(ATL_campus, nyc_campus, equal_var= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
